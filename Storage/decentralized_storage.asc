= Decentralized storage options for Public-Permissioned blockchain networks
:author: Jesus Ruiz
:email: hesus.ruiz@gmail.com
:revnumber: 0.3
:revdate: 05-09-2019
:numbered:
:icons: font
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
:bibtex-file: bibliography.bib
:bibtex-order: alphabetical
:bibtex-style: ieee

(Version: {revnumber}, Version Date: {revdate})

== Introduction

Storage of data in a blockchain system is a complex subject. There is not a single solution that
covers effectively all possible use cases and requirements. There is a tension between achieving
full decentralisation and the required degree of control, audibility, privacy and security that in
many uses cases is needed when managing the data.

However, there are some common patterns that can be identified and facilitates finding solutions to
their requirements. This document describes some options that can be adopted in order to facilitate
some specific use cases that we feel are very general.

To facilitate the discussion in this document, we are going to use a very simple taxonomy of data
and data transfer that we hope will be helpful. We are going to distinguish:

. *Personal data* vs *non-personal data*. It has strong legal implications and in general Personal
Data requires much more stringent measures providing privacy and confidentiality. It is subject to
legal requirements like data minimisation, consent, right to be forgotten, etc.

. *On-custody* or *owned-data*. The entity that stores the data can be the owner or can store it on
behalf of another entity. Special care should be taken when the stored data is personal data. In
some cases the user stores her own personal data in her own devices (mobile, hard disk, etc). A very
important case is when a legal entity (business, government, ...) stores and manages personal data
of a customer or citizen. Depending on the specific circumstances, that entity may be a Data
Controller or a Data Processor, but in any case, it is subject to very strict legal requirements as
set forth by GDPR.

. *Volume* of the data. Storing and transferring efficiently big amounts of data is harder than
small amounts of data. It is difficult to set a clear boundary, but in general small amounts of data
can be transferred in a "push" or "dissemination" model, while for big amounts of data it is better
to use a "pull" or "on-demand" model.

. *Model for transfer*: Transferring data from a source to one or more destinations in a network can
broadly follow several models:

.. *Push* model from the source to the target or target destinations. No other participant receives
the data.

.. *Dissemination (Broadcast)*, where the data is sent in push model to all participants, even if
there are participants who do not require the data. In this model, the participant which require the
data just accesses it locally. In this model, the data may be disseminated *on-clear* (like data
inside an Ethereum Smart Contract), or encrypted to restrict access

.. *Pull* model, where the data remains in the source but the participants which require the data
and are authorized to do so, access the data from the source when required.

== Personal data flow patterns

In this section we describe at a very high level the different data flow patterns that we normally
find when sending personal data from one entity to another. We will use later in this document these
patterns to describe in detail some considerations for EBSI decentralized storage systems.

=== Scenario 1: Data sent directly at the request of the user

image:assets/flow_user_e1_e2.png[]

This is the "classical" way of sending personal data from one entity to another (eg in a bank
transfer). In this model, the user logs-in into the system provided by Entity 1 (maybe using
userid/password), and performs an operation that causes some data to be sent to Entity 2.

Entity 1 is responsible for ensuring that the User is aware that her personal data is going to be
sent and obtaining appropriate consent, either per operation or in general when the user registered
for the service. In addition, it is responsible for logging such consent just in case it is required
by authorities.

We are not going to analyze further this model in this document.

=== Scenario 2: Data on-custody accessed by target entity with the consent from the user

image:assets/flow_user_e2_e1.png[]

An example of this pattern is when the user authorizes an energy to present the monthly bill to the
user's bank and get it paid automatically.

Another possibility is when the amount of data is too big to be sent with the "via the user"
pattern, or when the exact data needed by Entity 2 is not known in advance. In this last case, the
user is authorizing Entity 2 to access a subset of her data in the Entity 1 systems. This
autorization could be very simple or arbitrarily complex. Eg. with time limits, for a specific
purpose, etc.

This use-case can be considered when some (or all) of the following requirements have to be met:

. *Data on-custody:* the data is managed by a legal entity, not by a natural person. If the data
belongs to another entity, especially for a natural person, it is managed using an on-custody model
(https://en.wikipedia.org/wiki/Data_custodian). Depending on the specific circumstances, that entity
may be a Data Controller or a Data Processor, but in any case, it is subject to very strict legal
requirements as set forth by GDPR.

. **Strong privacy: **It may not desirable to disseminate the data among all the nodes (or even a
subset) in the network in a proactive (or *push*) way, even if encrypted.

. *Pull (on-demand) access:* the data can be accessed by the target organization only when needed
for processing, not necessarily at the same moment when the data is available.

. *Large amounts of data:* the data to be shared with other blockchain nodes is large (documents,
PDFs, videos, audios, etc).

. *Auditability of access:* we need to know *who* has accessed *what* data, *when* and for what
*purpose*..

=== The overall model of data on-custody use case

The overall process is the following:

. The data is either already available (eg. historical medical records) or is generated and stored
by the *origin* organization (eg. during a medical visit).

. A blockchain transaction is created, where the transaction holds on-chain a *safe pointer* to the
data to be shared with the target organization(s), which are a subset of the whole blockchain
network. That is, the data is not stored on-chain and is not necessarily available to all
organizations in the blockchain network. We use the term _safe pointer_ to refer to the
cryptographically protected hyperlinks described in IETF Hashlink system
(https://tools.ietf.org/html/draft-sporny-hashlink-00). The mechanisms described in the document
enables a system to publish a hyperlink in a way that empowers a consuming application to determine
if the resource associated with the hyperlink has changed in unexpected ways.

. The target organization(s), when they need the data, look at the transaction in the blockchain,
recover the pointer to the data in the transaction and use it to access the data from the origin
organization store, using a standard API and data model.

. The origin organization grants access to the data to the target organization(s) only if they are
authorised to access the data, possibly logging those actions for auditability.

. If the data is personal data managed by the origin organization (data controller according to
GDPR), the origin organization has to check that the target organization has explicit consent
enabling this action. We will see later how this can be accomplished using an SSI framework.

The following two figures describe a simple case where Institution 1 executes a blockchain
transaction where there is some data on-custody that has to be sent (or better said, make available)
to Institution 2, but not to the rest of the network.

The first figure describes a blockchain transaction written in the blockchain, with some data
on-chain and a pointer to the off-chain data associated with that transaction.

image:assets/On-custody1.png[]

The second figure describes Institution 2 accessing the off-chain data after reading the pointer
from the blockchain transaction, and Institution 3 being rejected access because it was not granted
access by Institution 1.

image:assets/On-custody2.png[]

The following sections zoom-in on some aspects of this approach.

=== The storage system in the origin organization

The data in the origin organization can be stored in an existing system or in a new one in the EBSI
platform, the latter option being the one depicted in the previous figures. The only requirement is
that the data can be accessed by other organisations in the network using standardised pointers
(URIs), API, access control and with a data model which is the same for all organisations in the
network. More on this later.

EBSI will provide an instance of this storage system as one of the components of the EBSI node,
ready to be used by the entity operating the node. But organisations are free to make other
implementations as long as they comply with the standard API and data model and that other
organisations can access the data in the same way, even if it does not reside physically inside the
EBSI node. One possible example could be when an organization implements the standard API as a layer
on top of a legacy system, potentially enabling access to that data using the new mechanisms.

In general, all organisations in EBSI should operate an instance of this system to store the data
that they have to manage in an on-custody model.

=== Standardized interfaces and mechanisms

To enable seamless interoperability among the members of EBSI, all participants should use the same
standard mechanisms and APIs to transfer and access data, independent on the underlying
implementations of the actual data storage systems in each organization. At the technical layer of
EBSI, the main aspects are:

. Safe pointer to the origin data.

. Standard API for data access operations (read/write/query/subscribe), not tied to a specific
database product or technology.

. A common meta model and data representation (eg. JSON-LD), enabling semantic interoperability and
data linking.

. A common access control mechanism to restrict data access to the authorised organizations,
according to a given policy (one-time access, time-based access, etc).

Based on the common meta model and data representation, each use case will build their specific data
models. This is domain-specific and will not be described in this document.

These aspects are elaborated in the following sections, with some recommendations for implementation
in EBSI.

=== Safe pointer to the origin data in the blockchain transaction: Hashlink

There are several possibilities for such a safe pointer. One simple way to store a secure pointer to
the origin data is to put in the transaction a URI and a hash of the data (to ensure that the data
has not been tampered with after the transaction is included in the blockchain). A standard way to
achieve that is the mechanism described above: the IETF Hashlink system (in draft mode
https://tools.ietf.org/html/draft-sporny-hashlink-00).

Once the Hashlink pointing to the origin data has been stored in the blockchain, the target
organisations can safely assume that the retrieved data from the origin organization is exactly the
same as was intended and that it has not been modified or tampered with in any way, if the hash of
the retrieved data matches with the one in the Hashlink.

In this way we use the power of the blockchain to enable the safe, private and efficient transfer of
data among organisations.

=== Common meta model and data representation: JSON-LD, Linked Data represented in JSON

As the W3C JSON-LD site (https://www.w3.org/TR/2014/REC-json-ld-20140116/) says:

____
JSON-LD is a lightweight syntax to serialize Linked Data in JSON
[RFC4627]. JSON-LD is primarily intended to be a way to use Linked Data
in Web-based programming environments, to build interoperable Web
services, and to store Linked Data in JSON-based storage engines. Since
JSON-LD is 100% compatible with JSON, the large number of JSON parsers
and libraries available today can be reused.
____

=== JSON-LD data management API and data model: Connecting Europe Facility (CEF) Context Broker

According to the CEF website
(https://ec.europa.eu/cefdigital/wiki/display/CEFDIGITAL/What+is+Context+Broker[What is Context
Broker]):

____
The CEF Context Broker enables organisations (including but not limited
to public administrations) to manage and share data in real-time. Thus,
for example, Smart Cities can share information about what is happening
in streets (e.g., traffic status, quality of air data, available parking
slots, location). Similarly, a packet delivery service company may share
data about orders (e.g., current location and expected delivery time).
This information describing what is currently happening is referred as
“context information”.
____


The CEF Context broker API is being extended and standardised as the ETSI NGSI-LD API
(https://www.etsi.org/deliver/etsi_gs/CIM/001_099/009/01.01.01_60/gs_CIM009v010101p.pdf).

The CEF Context Broker defines a standard API and Information Model which leverages the power of
Linked Data (https://www.w3.org/standards/semanticweb/data) to describe consistent models for data
coming from disparate sources. The Information Model is defined at two levels: the foundation
classes which correspond to the Core Meta-model and the Cross-Domain Ontology. For more detail,
please refer to the ETSI document referred before.

==== CEF Context Broker reference implementation

The ETSI NGSI-LD API can be implemented on top of different storage mechanisms and databases. For
EBSI a good option would be to use the reference Open Source implementation which has been already
used in production in different systems, most notably in Smart Cities and currently being expanded
to other use cases like Smart Industry. The
https://ec.europa.eu/cefdigital/wiki/display/CEFDIGITAL/Orion+Context+Broker[Orion Context Broker]
is such an implementation, and this is its Github: https://github.com/FIWARE/context.Orion-LD.

==== A common meta-model to describe the data exchanged among the member states and other organizations in EBSI

The CEF Context Broker API leverages the power of Linked Data to facilitate semantic
interoperability of the data exchanges across the different organisations. The core meta-model is
described in the following diagram:

image:assets/ngsi_metamodel.png[image,title="Blockchain Internal > Decentralized storage options for EBSI > image2019-8-25_0-38-32.png",width=800]

=== Access Control, leveraging ESSIF

The pointer to the data (URI + data hash) is stored in the blockchain transaction. When the target
organization(s) wants to access the data, the origin organization has to perform proper access
control mechanisms. In particular, if the data is personal data, the origin organization should
check that the target organization trying to access the data has the explicit consent of the
customer owning the data.

Thanks to SSI, we can implement a system which would be extremely difficult and cumbersome without
it.

==== Customer consent has to be represented as a Credential

In this on-custody model, when a target organization is accessing customer data which is held by an
origin organisation, the target organization has to prove to the origin organization that it has the
consent of the customer to do so.

Leveraging the SSI system, the customer has to previously send a special Credential to the target
organization authorising them to access data for a given purpose. In SSI terms, this is called a
Presentation, which is essentially a data packet containing one or more Credentials and a Purpose
and digitally signed by the customer.

The target organization has to present that Credential to the origin organization in order to be
able to access the data.

==== Access Control based on SSI Credentials from ESSIF

That means that the CEF Context Broker has to be extended with an access control system based on SSI
Credentials, where the credentials serve several purposes simultaneously:

. Identify the customer

. Prove that the customer has given consent to access a specific subset of her data in to another
organization

. That the data access is for a specific purpose and according to some conditions (eg. one-time
access, time-based access, etc)

. Using the SSI blockchain registry, the user can revoke authorisation to access her data at any
time

This is *extremely* difficult to achieve without an SSI system on top of a blockchain. The specifics
of this system should be developed jointly with the ESSIF team.

=== Detailed flow for transfer of data

The following diagram shows the detailed flow of data across two EBSI nodes.

image::assets/Storage_sequence1.png[]

The sequence is the following:

==== Store the off-chain data and write the transaction in the blockchain

**(1)** The Entity origin writes to its own node using the standard JSON-RPC interface for
blockchain transactions with two additional fields:

* An off-chain data field

* An access control field specifying the other entities who are autorized to access this data. This
  access control should be based on the ESSIF identities of the participant entities. More details
  on how this is specified later.

The proxy component in the EBSI node receives the request and:

**(2)** Stores the off-chain data in the EBSI node storage system using the standard NGSI-LD
interface of CEF Context Broker.

**(3)** Obtains a **safe pointer** for this data (URI + hash) and sets the access control
information for this pointer in the Access Control component in its own EBSI node.

**(4)** Writes the blockchain transaction with the safe pointer into the blockchain client, for
replication across the blockchain network.

**(5)** and **(6)** The transaction is included in the blockchain and an event is generated and
(possibly) received by the interested parties.

==== Entity 2 needs the data for processing

When the Entity 2 needs the data (not necessarily immediately after Entity 1 has made it available),
it sends a request to its own EBSI node (**(7)**):

**(8)** The proxy of Entity 2, using the safe pointer, calls the web-service of Entity 1 (actually
implemented by the proxy of Entity 1).

**(9)** The proxy of Entity 1 performs access conrol and logs the data access for auditing purposes
(who, when, what and for what purposes). More details later.

**(10), (11) and (12)** The proxy of Entity 1 retrieves the data and sends it back to Entity 2.

**(13)** The proxy of Entity 2 stores the data for cache purposes.

**(14)** The data is returned to Entity 2.

If the data is requested again, it is retrieved from the local cache (**(15), (16), (17) and (18)**)

== Scenario 3: Data sent via the user

In this model the data is sent via the user. This is in principle the main model used by
Self-Sovereign Identity schemes, where the user receives data from Entity 1 represented as
Credentials, and the user sends data to Entity 2 as Presentation objects including one or more
Credentials.

image:assets/flow_e1_user_e2.png[]

This pattern is also very common without the Verifiable Credentials. For example, when the user
gets a PDF document from one entity, and sends it to some other entity (eg. via email) to prove
something required for the provision of some service. All those use cases could be in principle be
better implemented with Verifiable Credentials in an SSI scheme.

The problem that this scenario presents is the storage of the personal data by the user,
specifically for the storage and exchange of Verifiable Credentials and associated data artifacts.
Ideally, the data is stored and managed autonomously by the end-user. In this scenario the data
exchange is always via the end-user, without any direct relationship or knowledge between the
credential issuers and the credential consumers.

The following sections explore some possibilities for the implementation of the *Secure Data Store*
concept from ESSIF when the owner is a natural person
(https://ec.europa.eu/cefdigital/wiki/display/EBP/Conceptual+architecture+%28ESSIF%29+iteration+3#Conceptualarchitecture(ESSIF)iteration3-CapabilityMap[Conceptual
architecture (ESSIF) iteration 3#CapabilityMap]).

=== Some possibilities: from mobile device storage to fully decentralised secure storage of personal data

Some possibilities for the Secure Data Store of EESIF for a natural person are:

==== Mobile device storage

The data is stored in the device storage. Ideally, the Credential data is stored encrypted and the
private key is stored in a secure element in the device. The private key used to sign the
Presentations is also stored in the secure element.

==== Mobile device storage complemented with an external hardware private key storage

It is basically the same approach as the previous one, with the exception that the private keys are
stored in a specialised external hardware device. An interesting possibility worth exploring is the
ability to use via NFC (on supported mobile devices) the digital certificate inside the secure eID
National Cards in some EU countries.

==== Data stored in a cloud provider (citizen choice), in addition to the mobile device storage

It is a variant of the previous approaches where the data is also stored in the cloud provider that
the citizen chooses (eg. Google Drive, Dropbox, One Drive, or even self-hosted for power users). The
data should be stored encrypted so the cloud provider does not have access to the data on the clear.
Many cloud services advertise that they already use encryption for the data their customers hold
with them, but it would be preferable to implement additional encryption at the ESSIF application
layer to ensure homogeneous behaviour independent from the cloud provider used.

If the user has more than one cloud provider, ESSIF could provide, if the user wishes so, the
ability to store the Credential data on several cloud providers at the same time in order to provide
an additional layer of resiliency and flexibility.

==== Data stored in EBSI-provided storage, in addition to the mobile device storage

For those users not having cloud providers, or not willing to use them for their personal data, EBSI
could provide a limited amount of free storage for Credential data. It is expected that the amount
of data requiring storage is relatively small, so EBSI could provide limited free storage services
that are automatically available and used for all users on-boarding the system. The limits will have
to be determined once more implementation data is available about the ESSIF system and use cases
taking advantage from it.

In this case, the most practical approach would be to provide a storage system with a standard
interface and a familiar paradigm for the user based on "files and folders", such as **Web
Distributed Authoring and Versioning** (**WebDAV**), which is an extension of the
https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol[Hypertext Transfer Protocol] (HTTP) that
allows https://en.wikipedia.org/wiki/Web_client[clients] to perform remote https://en.wikipedia.org/wiki/World_Wide_Web[Web]
content authoring operations. WebDAV is defined in https://en.wikipedia.org/wiki/Request_for_Comments_(identifier)[RFC]
https://tools.ietf.org/html/rfc4918[4918] by a https://en.wikipedia.org/wiki/Working_group[working group]
of the https://en.wikipedia.org/wiki/Internet_Engineering_Task_Force[Internet Engineering Task
Force].

WebDAV clients are implemented as a standard feature in most operating systems, including mobile
ones like Android and iOS.

image:assets/Other-web-storages.png[image,height=250] +

On the client side, WebDAV provides to the user the ability to navigate the data using the familiar
"files and folders" paradigm, which could be a good fit for Credential management (credentials are
in reality files, and folders could provide an easy-to-understand classification system). This would
provide the same user experience as when the personal data is stored in a "traditional" cloud
provider.

On the server side, there are several Open Source products that implement at least the basic
functionality required for the provision of this service by EBSI. One such possibility would be the
ownCloud project (https://github.com/owncloud/).

Most probably, each member state would have to provide such a service for their citizens, to reduce
complexities related to GDPR. With this model, personal data of a citizen would be stored in the
Secure Data Store instance provided by the member state of that citizen, as an additional mechanism
to the storage of that data in the mobile device of the user.

== Scenario 3: Secure personal data storage on a Self-Sovereign model in EBSI

The previous section dealt specifically with the storage of Credential data from ESSIF in EBSI.
Mostly the same considerations would apply if EBSI wishes to provide storage for citizens to store
other types of own data (e.g. diplomas or medical documents). However, the volume of data should be
taken into consideration and implement mechanisms to ensure the fair usage of the facilities.

_______________________

https://ec.europa.eu/cefdigital/wiki/display/~nitaiul[Iulian Florin NITA] To discuss! A research for
available open-source solutions for OFF-CHAIN storage (Distributed / Decentralized model) ( File
Storage vs Database)

*Distributed and Decentralized FILE STORAGE Systems*: IPFS, SIA, STORJ, PPIO, SWARM, BURST ,etc
https://medium.com/@ppio/what-is-decentralized-storage-9c4b761942e2 . The main issue here: the
deletion of the data from all the nodes can not be confirmed. The owner of the data can ask the
deletion of the data, it will be deleted from his own node and a broadcast will be sent in the
entire network. There is no warranty that the data will be deleted from all the peers in the
network.

*Distributed FILE Storage Systems*: it allows access to files from multiple hosts sharing via a p2p
network. This makes it possible for multiple users on multiple nodes to share files and storage
resources. A few well known open source projects in the market are: https://ceph.io/ ,
http://lustre.org/

_______

*Distributed and Decentralized DATABASES:* as far as I know there is no reliable and proven solution
in the market. Few projects are in development, but not very active: https://tiesdb.com/ ,
https://gun.eco/ , https://www.bigchaindb.com/

**Distributed Databases: **here is a matrix comparation between well know distributed databases:
https://db-engines.com/en/system/Cassandra%3BCouchDB%3BCouchbase%3BElasticsearch%3BMongoDB 

In my opinion, it looks like Cassandra DB could be a good choice, mainly because access rights for
users can be defined per object, but also for its advanced method for redundantly storing data on
multiple nodes.

!!! In general, in all cases, the distribution feature is ensured by replicating the data between
multiple nodes.

 +

 
